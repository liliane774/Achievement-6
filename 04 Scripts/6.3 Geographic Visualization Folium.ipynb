{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Geographic Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script contains the following:\n",
    "#### 1. Import data and libraries\n",
    "#### 2. Data wrangling\n",
    "#### 3. Data cleaning\n",
    "#### 4. Plotting a choropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command propts matplotlib visuals to appear in the notebook \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \".json\" file for the U.S. \n",
    "\n",
    "country_geo = r'C:/Users/asus/Documents/Work/Projects/Career Foundry/Data Analysis Immersion - Achievement 6 /us-states.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/asus/Documents/Career Foundry/Achievement 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the recipes data\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, '6.3 Images & Assets', 'Data', 'recipes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the necessary columns and put them in a list called columns\n",
    "\n",
    "columns = [\"alabama\",\n",
    "\"alaska\",\n",
    "\"arizona\",\n",
    "\"california\",\n",
    "\"colorado\",\n",
    "\"connecticut\",\n",
    "\"florida\",\n",
    "\"georgia\",\n",
    "\"hawaii\",\n",
    "\"idaho\",\n",
    "\"illinois\",\n",
    "\"indiana\",\n",
    "\"iowa\",\n",
    "\"kansas\",\n",
    "\"kentucky\",\n",
    "\"louisiana\",\n",
    "\"maine\",\n",
    "\"maryland\",\n",
    "\"massachusetts\",\n",
    "\"michigan\",\n",
    "\"minnesota\",\n",
    "\"mississippi\",\n",
    "\"missouri\",\n",
    "\"nebraska\",\n",
    "\"new hampshire\",\n",
    "\"new jersey\",\n",
    "\"new mexico\",\n",
    "\"new york\",\n",
    "\"north carolina\",\n",
    "\"ohio\",\n",
    "\"oklahoma\",\n",
    "\"oregon\",\n",
    "\"pennsylvania\",\n",
    "\"rhode island\",\n",
    "\"south carolina\",\n",
    "\"tennessee\",\n",
    "\"texas\",\n",
    "\"utah\",\n",
    "\"vermont\",\n",
    "\"virginia\",\n",
    "\"washington\",\n",
    "\"west virginia\",\n",
    "\"wisconsin\",\n",
    "\"title\",\n",
    "\"rating\",\n",
    "\"calories\",\n",
    "\"protein\",\n",
    "\"fat\",\n",
    "\"sodium\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset\n",
    "\n",
    "state_rec = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the states from state_rec in a new subset\n",
    "\n",
    "states_num = state_rec[[\"alabama\",\n",
    "\"alaska\",\n",
    "\"arizona\",\n",
    "\"california\",\n",
    "\"colorado\",\n",
    "\"connecticut\",\n",
    "\"florida\",\n",
    "\"georgia\",\n",
    "\"hawaii\",\n",
    "\"idaho\",\n",
    "\"illinois\",\n",
    "\"indiana\",\n",
    "\"iowa\",\n",
    "\"kansas\",\n",
    "\"kentucky\",\n",
    "\"louisiana\",\n",
    "\"maine\",\n",
    "\"maryland\",\n",
    "\"massachusetts\",\n",
    "\"michigan\",\n",
    "\"minnesota\",\n",
    "\"mississippi\",\n",
    "\"missouri\",\n",
    "\"nebraska\",\n",
    "\"new hampshire\",\n",
    "\"new jersey\",\n",
    "\"new mexico\",\n",
    "\"new york\",\n",
    "\"north carolina\",\n",
    "\"ohio\",\n",
    "\"oklahoma\",\n",
    "\"oregon\",\n",
    "\"pennsylvania\",\n",
    "\"rhode island\",\n",
    "\"south carolina\",\n",
    "\"tennessee\",\n",
    "\"texas\",\n",
    "\"utah\",\n",
    "\"vermont\",\n",
    "\"virginia\",\n",
    "\"washington\",\n",
    "\"west virginia\",\n",
    "\"wisconsin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command turns the dummy data from the states columns into a categorical variable in s2, which is a pandas Series data structure\n",
    "\n",
    "s2 = states_num.idxmax(axis=1)\n",
    "\n",
    "# You have not encountered Series yet, but it is another pandas data structure. It is similar to a dataframe, but it is \n",
    "# one-dimensional - this means it can only have one column, whereas a dataframe is two dimensional. You can turn any dataframe\n",
    "# column into series and you can add series to a dataframe as a column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column 'state' in the state_rec dataframe\n",
    "\n",
    "state_rec['STATE_NAME'] = s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dummy columns from the dataframe\n",
    "\n",
    "state_rec.drop(columns = [\"alabama\",\n",
    "\"alaska\",\n",
    "\"arizona\",\n",
    "\"california\",\n",
    "\"colorado\",\n",
    "\"connecticut\",\n",
    "\"florida\",\n",
    "\"georgia\",\n",
    "\"hawaii\",\n",
    "\"idaho\",\n",
    "\"illinois\",\n",
    "\"indiana\",\n",
    "\"iowa\",\n",
    "\"kansas\",\n",
    "\"kentucky\",\n",
    "\"louisiana\",\n",
    "\"maine\",\n",
    "\"maryland\",\n",
    "\"massachusetts\",\n",
    "\"michigan\",\n",
    "\"minnesota\",\n",
    "\"mississippi\",\n",
    "\"missouri\",\n",
    "\"nebraska\",\n",
    "\"new hampshire\",\n",
    "\"new jersey\",\n",
    "\"new mexico\",\n",
    "\"new york\",\n",
    "\"north carolina\",\n",
    "\"ohio\",\n",
    "\"oklahoma\",\n",
    "\"oregon\",\n",
    "\"pennsylvania\",\n",
    "\"rhode island\",\n",
    "\"south carolina\",\n",
    "\"tennessee\",\n",
    "\"texas\",\n",
    "\"utah\",\n",
    "\"vermont\",\n",
    "\"virginia\",\n",
    "\"washington\",\n",
    "\"west virginia\",\n",
    "\"wisconsin\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(state_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec['STATE_NAME'] = state_rec['STATE_NAME'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conduct consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "state_rec.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with median\n",
    "\n",
    "state_rec['calories'].fillna(state_rec['calories'].median(), inplace=True)\n",
    "state_rec['protein'].fillna(state_rec['protein'].median(), inplace=True)\n",
    "state_rec['fat'].fillna(state_rec['fat'].median(), inplace=True)\n",
    "state_rec['sodium'].fillna(state_rec['sodium'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last check for NaN\n",
    "\n",
    "state_rec.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = state_rec.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups.shape # no dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extreme values checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check how many extreme values\n",
    "\n",
    "state_rec[state_rec['fat'] >1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extreme values\n",
    "\n",
    "state_rec = state_rec[state_rec['fat'] < 500] \n",
    "# 500 was picked because it is beyond belief there could be a meal with over 500 gr of fat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'cal_per_portion' column\n",
    "\n",
    "state_rec['cal_per_portion'] = state_rec['calories']*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(state_rec['cal_per_portion'], bins=20, kde = True)  # shows extreme values for 'cal_per_portion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extreme values in 'cal_per_portion'\n",
    "\n",
    "state_rec = state_rec[state_rec['cal_per_portion'] < 8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rating variable\n",
    "\n",
    "sns.histplot(state_rec['rating'], bins=20, kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only entries with a non-zero rating\n",
    "\n",
    "state_rec = state_rec[state_rec['rating'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rec.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plotting a choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with just the states and the values for rating we want plotted\n",
    "\n",
    "data_to_plot = state_rec[['STATE_NAME','rating']]\n",
    "data_to_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a folium map at a high-level zoom\n",
    "map = folium.Map(location = [100, 0], zoom_start = 1.5)\n",
    "\n",
    "# Choropleth maps bind Pandas Data Frames and json geometries.This allows us to quickly visualize data combinations\n",
    "folium.Choropleth(\n",
    "    geo_data = country_geo, \n",
    "    data = data_to_plot,\n",
    "    columns = ['STATE_NAME', 'rating'],\n",
    "    key_on = 'feature.properties.name', # this part is very important - check your json file to see where the KEY is located\n",
    "    fill_color = 'YlOrBr', fill_opacity=0.6, line_opacity=0.1,\n",
    "    legend_name = \"rating\").add_to(map)\n",
    "folium.LayerControl().add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.save('plot_data.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
